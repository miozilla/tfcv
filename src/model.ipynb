{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c088df3-2c9e-4973-95ae-31a69a7094c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:18:01.181156Z",
     "iopub.status.busy": "2026-02-13T07:18:01.179613Z",
     "iopub.status.idle": "2026-02-13T07:18:02.076039Z",
     "shell.execute_reply": "2026-02-13T07:18:02.074656Z",
     "shell.execute_reply.started": "2026-02-13T07:18:01.181087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.cloud.appengine_logging_v1 once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.cloud.appengine_logging_v1 past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import and configure logging\n",
    "import logging\n",
    "import google.cloud.logging as cloud_logging\n",
    "from google.cloud.logging.handlers import CloudLoggingHandler\n",
    "from google.cloud.logging_v2.handlers import setup_logging\n",
    "\n",
    "cloud_logger = logging.getLogger('cloudLogger')\n",
    "cloud_logger.setLevel(logging.INFO)\n",
    "cloud_logger.addHandler(CloudLoggingHandler(cloud_logging.Client()))\n",
    "cloud_logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52942e6-a421-46c9-aadb-21989b2c4acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:18:33.275655Z",
     "iopub.status.busy": "2026-02-13T07:18:33.274651Z",
     "iopub.status.idle": "2026-02-13T07:18:37.994763Z",
     "shell.execute_reply": "2026-02-13T07:18:37.993555Z",
     "shell.execute_reply.started": "2026-02-13T07:18:33.275609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 07:18:33.799020: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-02-13 07:18:33.856551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-13 07:18:33.856599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-13 07:18:33.858429: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-13 07:18:33.868484: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-02-13 07:18:33.869685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87b639f-557d-4c38-bdbb-daa50aa6e4c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:19:21.176716Z",
     "iopub.status.busy": "2026-02-13T07:19:21.175238Z",
     "iopub.status.idle": "2026-02-13T07:19:21.184592Z",
     "shell.execute_reply": "2026-02-13T07:19:21.181207Z",
     "shell.execute_reply.started": "2026-02-13T07:19:21.176670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8570975e-099d-4cac-b6c8-6d4d81bcee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:19:54.528628Z",
     "iopub.status.busy": "2026-02-13T07:19:54.525329Z",
     "iopub.status.idle": "2026-02-13T07:19:54.770270Z",
     "shell.execute_reply": "2026-02-13T07:19:54.768786Z",
     "shell.execute_reply.started": "2026-02-13T07:19:54.528555Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import tensorflow_datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279c4492-36d3-4e92-8d05-f5f3f2775d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:21:33.560011Z",
     "iopub.status.busy": "2026-02-13T07:21:33.558631Z",
     "iopub.status.idle": "2026-02-13T07:22:00.782312Z",
     "shell.execute_reply": "2026-02-13T07:22:00.780878Z",
     "shell.execute_reply.started": "2026-02-13T07:21:33.559961Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder /home/jupyter/tensorflow_datasets/fashion_mnist/3.0.1 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/jupyter/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409892dbec7c4058aa2c3eac44277b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7fa93c4c9d4d2599b563e63079d01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a64a293f4c4f82ab1f2a67c58397a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cfd8906fb64688a8d3ecc58a21688e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dd31fc92844351bb450c234e846f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8281e7facdf4afba76bbb9602083634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jupyter/tensorflow_datasets/fashion_mnist/incomplete.N3RMWT_3.0.1/fashion_mnist-train.tfrecord…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a022d6f07f4149b7647f24cbcf32be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b9b655ab5b49009d144d3142f06fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jupyter/tensorflow_datasets/fashion_mnist/incomplete.N3RMWT_3.0.1/fashion_mnist-test.tfrecord*…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to /home/jupyter/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define, load and configure data\n",
    "(ds_train, ds_test), info = tfds.load('fashion_mnist', split=['train', 'test'], with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84dc079a-cfbf-4ebe-a95b-4e192063aa42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:22:45.466853Z",
     "iopub.status.busy": "2026-02-13T07:22:45.466354Z",
     "iopub.status.idle": "2026-02-13T07:22:45.556474Z",
     "shell.execute_reply": "2026-02-13T07:22:45.554152Z",
     "shell.execute_reply.started": "2026-02-13T07:22:45.466813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization -> 0 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 07:22:45.537992: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Values before normalization\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "print(\"Before normalization ->\", np.min(image_batch[0]), np.max(image_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8fcd614-d7c4-4daf-80c4-dfe81c76a7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:23:04.373034Z",
     "iopub.status.busy": "2026-02-13T07:23:04.372459Z",
     "iopub.status.idle": "2026-02-13T07:23:04.379030Z",
     "shell.execute_reply": "2026-02-13T07:23:04.377550Z",
     "shell.execute_reply.started": "2026-02-13T07:23:04.372978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d790f11-9c82-453d-978a-c7fe0547c5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:23:15.525489Z",
     "iopub.status.busy": "2026-02-13T07:23:15.524642Z",
     "iopub.status.idle": "2026-02-13T07:23:15.608839Z",
     "shell.execute_reply": "2026-02-13T07:23:15.607564Z",
     "shell.execute_reply.started": "2026-02-13T07:23:15.525444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize and batch process the dataset\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)\n",
    "ds_test = ds_test.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a793ed-b265-4873-ad58-05ad1be16554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:23:25.914867Z",
     "iopub.status.busy": "2026-02-13T07:23:25.914165Z",
     "iopub.status.idle": "2026-02-13T07:23:26.008445Z",
     "shell.execute_reply": "2026-02-13T07:23:26.007047Z",
     "shell.execute_reply.started": "2026-02-13T07:23:25.914813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization -> 0.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 07:23:25.996612: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Examine the min and max values of the batch after normalization\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "print(\"After normalization ->\", np.min(image_batch[0]), np.max(image_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7411e9a8-8c99-412c-bd91-100f3734cfdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:24:07.807813Z",
     "iopub.status.busy": "2026-02-13T07:24:07.806873Z",
     "iopub.status.idle": "2026-02-13T07:24:07.867163Z",
     "shell.execute_reply": "2026-02-13T07:24:07.864741Z",
     "shell.execute_reply.started": "2026-02-13T07:24:07.807763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdae353f-6af6-4a44-b7bb-574a9997044b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:24:44.869732Z",
     "iopub.status.busy": "2026-02-13T07:24:44.868528Z",
     "iopub.status.idle": "2026-02-13T07:25:58.764146Z",
     "shell.execute_reply": "2026-02-13T07:25:58.762686Z",
     "shell.execute_reply.started": "2026-02-13T07:24:44.869670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.5175 - sparse_categorical_accuracy: 0.8181\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.8593\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3559 - sparse_categorical_accuracy: 0.8715\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3307 - sparse_categorical_accuracy: 0.8803\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3124 - sparse_categorical_accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd45bbe8bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "model.fit(ds_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309b79b3-32c3-436e-8234-3e05bafd63e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:27:00.555910Z",
     "iopub.status.busy": "2026-02-13T07:27:00.555446Z",
     "iopub.status.idle": "2026-02-13T07:27:05.932967Z",
     "shell.execute_reply": "2026-02-13T07:27:05.931392Z",
     "shell.execute_reply.started": "2026-02-13T07:27:00.555862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3575 - sparse_categorical_accuracy: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0.35754334926605225, 0.873199999332428]\n",
      "INFO:cloudLogger:[0.35754334926605225, 0.873199999332428]\n"
     ]
    }
   ],
   "source": [
    "cloud_logger.info(model.evaluate(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4d4d68-6910-47d7-9a6a-097ef94bea87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T07:28:13.943034Z",
     "iopub.status.busy": "2026-02-13T07:28:13.941296Z",
     "iopub.status.idle": "2026-02-13T07:28:14.305711Z",
     "shell.execute_reply": "2026-02-13T07:28:14.304733Z",
     "shell.execute_reply.started": "2026-02-13T07:28:13.942972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a Keras model using .keras format\n",
    "model.save('saved_model.keras') \n",
    "\n",
    "# Load the model using custom_objects to handle the custom activation function\n",
    "new_model = tf.keras.models.load_model('saved_model.keras', custom_objects={'softmax_v2': tf.keras.activations.softmax})\n",
    "\n",
    "# Summary of loaded SavedModel\n",
    "new_model.summary()\n",
    "\n",
    "# Save the entire model to a keras file.\n",
    "model.save('my_model.keras')\n",
    "\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model_keras = tf.keras.models.load_model('my_model.keras', custom_objects={'softmax_v2': tf.keras.activations.softmax})\n",
    "\n",
    "# Summary of loaded keras model\n",
    "new_model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a803298-a199-46f3-bf56-16e0a1ec1cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m139",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m139"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
